{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a las Redes Neuronales\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué son las Redes Neuronales?\n",
    "\n",
    "Las Redes Neuronales Artificiales (ANNs) son modelos de computación inspirados en el cerebro humano. Consisten en capas de nodos, muy parecidos a las neuronas en el cerebro humano. Las redes neuronales pueden aprender patrones complejos y relaciones en los datos, lo que las hace particularmente eficaces para tareas como la clasificación de imágenes, el procesamiento del lenguaje natural, y la predicción en series temporales.\n",
    "\n",
    "Una red neuronal típicamente consta de tres tipos de capas:\n",
    "\n",
    "1. **Capa de entrada**: Recibe los datos de entrada y los pasa a la primera capa oculta.\n",
    "2. **Capas ocultas**: Aquí es donde ocurre la mayor parte del cálculo. Cada nodo en una capa oculta representa una combinación de entradas de nodos en capas anteriores.\n",
    "3. **Capa de salida**: Produce la predicción o clasificación de la red.\n",
    "\n",
    "Cada conexión entre nodos tiene un peso, y cada nodo tiene una función de activación que transforma sus entradas en una salida.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Redes Neuronales\n",
    "\n",
    "Existen varios tipos de redes neuronales, cada una con sus características y usos específicos. Algunos de los tipos más comunes son:\n",
    "\n",
    "### 1. Redes Neuronales de Alimentación hacia Adelante (Feedforward Neural Networks)\n",
    "![FNN](https://upload.wikimedia.org/wikipedia/en/5/54/Feed_forward_neural_net.gif)\n",
    "\n",
    "Estas redes son la forma más simple de redes neuronales. En ellas, la información se mueve en una sola dirección, desde la capa de entrada, a través de las capas ocultas, y finalmente a la capa de salida. No hay ciclos o bucles en la red, la información siempre se mueve hacia adelante. Se utilizan principalmente para tareas de regresión y clasificación.\n",
    "\n",
    "### 2. Redes Neuronales Convolucionales (CNNs)\n",
    "![CNNs](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/627d1225cb1b3d197840427a_60f040a887535b932a3b2b6e_cnn-hero%2520(1).png)\n",
    "\n",
    "Las CNNs son especialmente efectivas para tareas que involucran datos con estructura de cuadrícula, como imágenes. Las CNNs utilizan operaciones de convolución para procesar los datos, lo que les permite considerar la estructura espacial de los datos. Esto las hace muy eficientes para tareas como reconocimiento de imágenes y procesamiento de video.\n",
    "\n",
    "### 3. Redes Neuronales Recurrentes (RNNs)\n",
    "![RNNs](https://www.simplilearn.com/ice9/free_resources_article_thumb/Simple_Recurrent_Neural_Network.png)\n",
    "\n",
    "Las RNNs son adecuadas para tareas con datos secuenciales como series temporales o secuencias de texto. A diferencia de las redes de alimentación hacia adelante, las RNNs tienen conexiones que forman ciclos, permitiéndoles mantener un estado que puede representar información sobre la secuencia de datos hasta el momento. Sin embargo, a menudo tienen dificultades para aprender dependencias a largo plazo debido a problemas como el desvanecimiento del gradiente.\n",
    "\n",
    "### 4. Long Short Term Memory Networks (LSTMs)\n",
    "![LSTMs](https://wiki.pathmind.com/images/wiki/gates_lstm.png)\n",
    "Las LSTMs son una variante especial de RNNs diseñada específicamente para abordar el problema del desvanecimiento del gradiente y son más eficaces en aprender dependencias a largo plazo. Tienen una estructura de celda de memoria más compleja que les permite regular mejor el flujo de información.\n",
    "\n",
    "### 5. Redes Generativas Adversarias (GANs)\n",
    "![GANs](https://www.researchgate.net/publication/335958906/figure/fig2/AS:805410340618243@1569036197891/The-multi-task-GAN-network-structure-The-generator-network-adopts-U-Net-24-structure.ppm)\n",
    "\n",
    "Las GANs constan de dos redes, una red generativa que produce datos y una red discriminativa que intenta distinguir entre datos reales y generados. Al entrenarse juntas, la red generativa aprende a producir datos que son indistinguibles de los reales. Se usan en tareas como la generación de imágenes, super-resolución, y transferencia de estilo.\n",
    "\n",
    "### 6. Autoencoders\n",
    "![autoencoders](https://media.licdn.com/dms/image/D5612AQGwukGP_-Lx3Q/article-cover_image-shrink_720_1280/0/1680315209282?e=2147483647&v=beta&t=0mAm80uK4ttEHUtF7FViq7NjMyLlQxTeXRkvFz9YO7E)\n",
    "\n",
    "Los autoencoders son redes neuronales utilizadas para aprender representaciones eficientes de datos, típicamente para el propósito de reducción de dimensionalidad. Un autoencoder consta de dos partes, un codificador que comprime la entrada en una representación latente, y un decodificador que reconstruye la entrada a partir de esta representación.\n",
    "\n",
    "### 7. Redes de Atención y Transformers\n",
    "\n",
    "Las redes de atención son una clase de modelos que aprenden a ponderar diferentes partes de los datos de entrada cuando realizan una tarea, en lugar de depender por igual de todas las partes de la entrada. Los Transformers son un tipo específico de red de atención que se ha vuelto muy popular, especialmente en el procesamiento del lenguaje natural, y son la base de modelos como GPT y BERT.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Datos MNIST\n",
    "\n",
    "El conjunto de datos que vamos a utilizar para este proyecto se llama **MNIST** (Modified National Institute of Standards and Technology database). Es uno de los conjuntos de datos más emblemáticos en el campo del aprendizaje automático y la visión por computadora.\n",
    "\n",
    "### Características del conjunto de datos MNIST:\n",
    "\n",
    "- **Imágenes en escala de grises**: Contiene 70,000 imágenes en escala de grises de dígitos escritos a mano (del 0 al 9).\n",
    "\n",
    "- **Tamaño de las imágenes**: Las imágenes son de un tamaño pequeño, específicamente de 28x28 píxeles.\n",
    "\n",
    "- **División de datos**: De las 70,000 imágenes, 60,000 están destinadas para entrenamiento y 10,000 para pruebas.\n",
    "\n",
    "- **Etiquetas**: Las etiquetas están representadas como números enteros del 0 al 9 y corresponden al dígito que la imagen representa.\n",
    "\n",
    "MNIST es a menudo utilizado en tareas de clasificación de imágenes y reconocimiento de dígitos manuscritos. Se considera como el \"Hola Mundo\" del aprendizaje profundo debido a que es comúnmente el primer conjunto de datos con el que los practicantes experimentan.\n",
    "\n",
    "Este conjunto de datos es ideal para principiantes porque, aunque es relativamente simple, ofrece suficiente desafío como para aprender diferentes aspectos del entrenamiento de modelos de aprendizaje profundo.\n",
    "\n",
    "En nuestro código, el conjunto de datos MNIST se carga fácilmente utilizando la función `mnist.load_data()` proporcionada por TensorFlow. Esto facilita enormemente el acceso y uso del conjunto de datos sin la necesidad de procesos manuales de descarga y preprocesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 22:20:14.739675: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-07 22:20:14.775166: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-07 22:20:15.034463: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-07 22:20:15.035871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 22:20:15.963133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#conjunto de datos MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f033ffbc430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vemos un ejemplo de imagen\n",
    "\n",
    "plt.imshow(train_images[2], cmap='gray', interpolation='bicubic')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reescalado de las Imágenes\n",
    "\n",
    "En la etapa de preprocesamiento de los datos, una práctica común es reescalar los valores de los píxeles de las imágenes. Originalmente, los valores de los píxeles en las imágenes en escala de grises están en el rango de 0 a 255, donde 0 representa el color negro y 255 representa el color blanco. Los valores intermedios representan diversos tonos de gris.\n",
    "\n",
    "### ¿Por qué reescalamos las imágenes?\n",
    "\n",
    "El reescalado de las imágenes se realiza para ayudar a la convergencia del modelo durante el entrenamiento. Al reescalar los valores de los píxeles a un rango de 0 a 1, estamos normalizando los datos de entrada. La normalización de los datos de entrada es beneficiosa porque ayuda a evitar que los valores de los gradientes se vuelvan demasiado grandes o demasiado pequeños, lo que puede llevar a que el algoritmo de entrenamiento sea inestable o tarde mucho en converger.\n",
    "\n",
    "### ¿Cómo lo hacemos?\n",
    "\n",
    "El código que realiza este reescalado es el siguiente:\n",
    "\n",
    "```python\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reescalamos las imágenes para que los valores de los píxeles estén en el rango [0, 1]\n",
    "# Esto ayuda a la convergencia del modelo\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de Etiquetas a Codificación One-Hot\n",
    "\n",
    "Después de reescalar las imágenes, el siguiente paso en el preprocesamiento es convertir las etiquetas a la codificación one-hot.\n",
    "\n",
    "### ¿Qué es la Codificación One-Hot?\n",
    "\n",
    "La codificación one-hot es una representación de variables categóricas como vectores binarios. En nuestro caso, las etiquetas son números enteros del 0 al 9, que representan los dígitos escritos a mano. Para convertir estas etiquetas a la codificación one-hot, creamos un vector de longitud 10 (número de clases) para cada etiqueta, donde todas las entradas son 0, excepto para el índice que corresponde a la etiqueta, que se establece en 1.\n",
    "\n",
    "Por ejemplo, la etiqueta `2` se convierte en el vector `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]`.\n",
    "\n",
    "### ¿Por qué usar la Codificación One-Hot?\n",
    "\n",
    "El uso de la codificación one-hot es beneficioso cuando trabajamos con problemas de clasificación multiclase, como el nuestro. Al entrenar la red neuronal, queremos que la salida sea una distribución de probabilidad entre las diferentes clases. La codificación one-hot permite una comparación más natural entre la salida de la red y la etiqueta verdadera.\n",
    "\n",
    "### Código para la Conversión a Codificación One-Hot\n",
    "\n",
    "```python\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos las etiquetas (números enteros) a codificación one-hot\n",
    "# Por ejemplo, convertimos la etiqueta 2 en [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de la Arquitectura de la Red Neuronal Convolucional (CNN)\n",
    "\n",
    "Una Red Neuronal Convolucional (CNN) es un tipo de red neuronal artificial que es especialmente poderosa para tareas como el reconocimiento de imágenes. Las CNNs son capaces de identificar patrones jerárquicos en los datos, lo que las hace muy adecuadas para identificar formas, texturas, y objetos en imágenes.\n",
    "\n",
    "Vamos a construir una CNN simple pero efectiva para nuestro problema de clasificación de dígitos escritos a mano.\n",
    "\n",
    "### Inicializando un Modelo Secuencial\n",
    "\n",
    "Inicializamos un modelo secuencial. Un modelo secuencial es un tipo de modelo que consiste en una pila lineal de capas. Esto significa que podemos agregar capas una tras otra en el orden en que queremos que los datos fluyan.\n",
    "\n",
    "### Primera Capa Convolucional\n",
    "\n",
    "Esta es la primera capa convolucional y la capa de entrada de nuestra red. Esta capa aprende 32 filtros y usa un kernel de tamaño 3x3. \n",
    "\n",
    "- **32**: Número de filtros que la capa convolucional aprenderá. Cada filtro es capaz de detectar una característica específica en la imagen.\n",
    "- **(3, 3)**: Tamaño del kernel convolucional. Un kernel de 3x3 significa que el filtro tiene 3 píxeles de ancho y 3 píxeles de alto.\n",
    "- **activation='relu'**: Función de activación ReLU (Rectified Linear Unit). Esta función de activación es muy común y ayuda a introducir la no linealidad en el modelo.\n",
    "- **input_shape=(28, 28, 1)**: Es la forma de los datos de entrada. Cada imagen es de 28x28 píxeles con un solo canal de color (escala de grises).\n",
    "\n",
    "### Primera Capa de Max Pooling\n",
    "\n",
    "Esta capa realiza una operación de Max Pooling con un filtro de tamaño 2x2. Lo que hace es reducir la dimensión espacial de la entrada (ancho y alto) tomando el máximo valor en cada ventana de 2x2 píxeles. Esto ayuda a reducir la cantidad de parámetros y computación en la red, y también ayuda a extraer características más robustas.\n",
    "\n",
    "### Segunda Capa Convolucional y Segunda Capa de Max Pooling\n",
    "\n",
    "Estas capas son similares a las primeras, pero esta vez la capa convolucional aprende 64 filtros. Al incrementar el número de filtros en las capas más profundas, la red puede aprender características más complejas.\n",
    "\n",
    "### Tercera Capa Convolucional\n",
    "\n",
    "Finalmente, agregamos una tercera capa convolucional que también aprende 64 filtros con un kernel de 3x3. No seguimos esto con otra capa de Max Pooling porque la dimensión de la entrada ya se ha reducido lo suficiente.\n",
    "\n",
    "Estas capas trabajan juntas para recibir imágenes de dígitos escritos a mano y transformarlas a través de una serie de convoluciones y reducciones de dimensiones, de manera que las características importantes de las imágenes sean capturadas y estén listas para ser clasificadas en las siguientes capas.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los Pesos en Redes Neuronales\n",
    "\n",
    "En las redes neuronales, los **pesos** son valores numéricos asociados a las conexiones entre las neuronas. Son uno de los componentes más importantes en una red neuronal, ya que determinan cómo las señales entre neuronas se modulan durante el proceso de aprendizaje y predicción.\n",
    "\n",
    "### ¿Qué hacen los pesos?\n",
    "\n",
    "Cuando una neurona recibe datos de entrada, multiplica cada entrada por un peso, y luego suma estos productos. Los pesos determinan la importancia relativa de cada entrada para el cálculo realizado por la neurona. Esencialmente, si el peso es alto, la neurona considerará que esa entrada en particular es más importante que si el peso es bajo.\n",
    "\n",
    "### Inicialización de los pesos\n",
    "\n",
    "Al comienzo del entrenamiento, los pesos se inicializan generalmente con valores pequeños y aleatorios. Esto se hace para romper cualquier simetría que pudiera existir y permitir que la red neuronal aprenda de manera más efectiva.\n",
    "\n",
    "Hay varias estrategias para inicializar los pesos, como la inicialización uniforme, la inicialización normal y la inicialización de He o Glorot, que están diseñadas para establecer los pesos de manera que faciliten la convergencia durante el entrenamiento.\n",
    "\n",
    "### Aprendizaje y ajuste de los pesos\n",
    "\n",
    "Durante el proceso de entrenamiento, el objetivo es ajustar los pesos de tal manera que minimicen una función de pérdida, que mide cuán lejos están las predicciones de la red de los valores verdaderos.\n",
    "\n",
    "Utilizando algoritmos como el descenso de gradiente, se calcula cómo una pequeña variación en cada peso afectaría a la función de pérdida, y luego se ajustan los pesos en la dirección que reduce la pérdida.\n",
    "\n",
    "### Regularización de los pesos\n",
    "\n",
    "A veces, durante el entrenamiento, ciertos pesos pueden crecer demasiado, lo que puede llevar a un sobreajuste, donde la red se vuelve muy especializada en los datos de entrenamiento y no generaliza bien a datos nuevos.\n",
    "\n",
    "Para evitar esto, a menudo se utiliza la regularización, que es una técnica que agrega un término a la función de pérdida que penaliza los pesos grandes. Esto fomenta que la red neuronal tenga pesos más pequeños y sea más capaz de generalizar a datos no vistos.\n",
    "\n",
    "### Resumen\n",
    "\n",
    "- Los pesos determinan la importancia relativa de las entradas en los cálculos de las neuronas.\n",
    "- Se inicializan con valores pequeños y aleatorios y se ajustan durante el entrenamiento.\n",
    "- La regularización se utiliza para evitar que los pesos crezcan demasiado y causen sobreajuste.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué significa un Kernel 3x3?\n",
    "\n",
    "En una Red Neuronal Convolucional (CNN), un \"kernel\" se refiere a una pequeña matriz de pesos que se utiliza para realizar la operación de convolución. Cuando se convoluciona una imagen con este kernel, se realiza un producto elemento por elemento y una suma sobre una región de 3x3 píxeles de la imagen de entrada, y el resultado se almacena en la imagen de salida (mapa de características). Esto se repite desplazando el kernel a través de toda la imagen. \n",
    "\n",
    "Específicamente, un kernel de 3x3 tiene la siguiente forma: </br></br>\n",
    "| w1 w2 w3 | </br>\n",
    "| w4 w5 w6 | </br>\n",
    "| w7 w8 w9 | </br>\n",
    "\n",
    "Donde `w1` a `w9` representan los pesos. Esta matriz de 3x3 se superpone con una región de 3x3 de la imagen de entrada y se realiza una combinación lineal de los valores de los píxeles y los pesos del kernel.\n",
    "\n",
    "La convolución ayuda a detectar características locales en la imagen, como bordes, texturas y patrones. Al ajustar los pesos en el kernel durante el entrenamiento, la red neuronal aprende qué características son importantes para hacer predicciones precisas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos la arquitectura de la Red Neuronal Convolucional\n",
    "\n",
    "# Inicializamos un modelo secuencial\n",
    "model = models.Sequential([\n",
    "    # Primera capa convolucional: aprende 32 filtros usando un kernel de 3x3\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Primera capa de Max Pooling: reduce dimensionalidad a la mitad (14x14)\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Segunda capa convolucional: aprende 64 filtros usando un kernel de 3x3\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Segunda capa de Max Pooling: reduce dimensionalidad a la mitad (7x7)\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Tercera capa convolucional: aprende 64 filtros usando un kernel de 3x3\n",
    "    layers.Conv2D(64, (3, 3), activation='relu')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplanado de la Salida de las Capas Convolucionales\n",
    "\n",
    "Después de pasar por varias capas convolucionales y de pooling, la salida es un tensor tridimensional con dimensiones (altura, ancho, canales). Sin embargo, las capas densas o completamente conectadas, esperan que los datos de entrada estén en forma de vectores unidimensionales.\n",
    "\n",
    "La operación de **aplanado** (flattening) se utiliza para convertir el tensor tridimensional en un vector unidimensional, alineando todos los valores en un largo vector. Esto se realiza de modo que podamos alimentar los datos a las capas densas.\n",
    "\n",
    "```python\n",
    "model.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanamos la salida de las capas convolucionales\n",
    "# De modo que podamos alimentarla a una capa densa (completamente conectada)\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo una Capa Densa\n",
    "\n",
    "Una capa densa o completamente conectada es una capa en la cual cada neurona está conectada a todas las neuronas de la capa anterior. Esto significa que cada neurona recibe como entrada un valor ponderado de cada neurona de la capa anterior.\n",
    "\n",
    "En nuestro modelo, añadimos una capa densa con la siguiente línea de código:\n",
    "\n",
    "```python\n",
    "model.add(layers.Dense(64, activation='relu'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función ReLU es una función simple definida como ReLU(x) = max(0, x). Esto significa que si la entrada es positiva, la función devuelve la entrada sin cambios, mientras que si es negativa, devuelve 0. ReLU es popular en redes neuronales porque es computacionalmente eficiente y ayuda a mitigar el problema del desvanecimiento del gradiente, lo que permite que las redes neuronales profundas aprendan más eficazmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa Densa con 64 neuronas y función de activación ReLU\n",
    "model.add(layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo la Capa de Salida\n",
    "\n",
    "La capa de salida de nuestra red neuronal es responsable de producir las predicciones finales. En problemas de clasificación, como el reconocimiento de dígitos, la capa de salida tiene generalmente tantas neuronas como clases haya para predecir. En este caso, tenemos 10 clases (los dígitos del 0 al 9), por lo que la capa de salida tiene 10 neuronas.\n",
    "\n",
    "En la capa de salida, utilizamos la función de activación **softmax**. Esta función convierte un vector de números reales en probabilidades que suman 1. Esto nos permite interpretar las salidas de la red como probabilidades de que la entrada pertenezca a cada una de las clases.\n",
    "\n",
    "Aquí está el código que agrega la capa de salida:\n",
    "\n",
    "```python\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa de salida con 10 neuronas (una por cada clase 0-9) y función de activación softmax\n",
    "# Que nos da la probabilidad de que la entrada pertenezca a cada clase\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación del Modelo\n",
    "\n",
    "Una vez que hemos construido la arquitectura de la red neuronal, el siguiente paso es compilar el modelo. Compilar el modelo implica configurar el proceso de aprendizaje antes de entrenar el modelo con los datos. Para compilar el modelo, necesitamos especificar al menos tres elementos clave: el optimizador, la función de pérdida y las métricas de evaluación.\n",
    "\n",
    "### Optimizador\n",
    "\n",
    "El optimizador es el algoritmo que se utiliza para actualizar los pesos de la red durante el entrenamiento. En este caso, se está utilizando el optimizador 'adam'. Adam es un optimizador de gradiente estocástico ampliamente utilizado porque combina las ventajas de otros dos optimizadores populares - AdaGrad y RMSProp.\n",
    "\n",
    "### Función de Pérdida\n",
    "\n",
    "La función de pérdida es una métrica que mide cuán bien el modelo está realizando el aprendizaje durante el entrenamiento. Queremos minimizar esta función, lo que se traduciría en mejorar la precisión del modelo. En este caso, para un problema de clasificación multiclase como el nuestro, se utiliza 'categorical_crossentropy' como función de pérdida.\n",
    "\n",
    "### Métricas\n",
    "\n",
    "Las métricas son utilizadas para monitorear el rendimiento del modelo. No afectan el funcionamiento del modelo, pero son importantes para evaluar su desempeño. En este caso, se está utilizando 'accuracy' como métrica, que calcula la precisión de las clasificaciones realizadas por el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificamos el optimizador, la función de pérdida y las métricas para el entrenamiento\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo\n",
    "\n",
    "Ahora que hemos compilado nuestro modelo, el siguiente paso es entrenarlo utilizando los datos de entrenamiento. Para hacerlo, utilizamos la función `fit` de Keras.\n",
    "\n",
    "```python\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a desglosar los componentes de esta función:\n",
    "\n",
    "- `model.fit()`: Esta es la función que realmente entrena el modelo. Se encarga de ajustar los pesos de la red neuronal utilizando los datos de entrenamiento que se le proporcionan.\n",
    "\n",
    "- `train_images`: Son los datos de entrada que se utilizan para entrenar el modelo.\n",
    "\n",
    "- `train_labels`: Son las etiquetas correctas asociadas a los datos de entrenamiento. El modelo intentará aprender a predecir estas etiquetas a partir de las imágenes de entrenamiento.\n",
    "\n",
    "- `epochs=5`: Especifica el número de épocas, donde una época es una iteración completa sobre todo el conjunto de datos de entrenamiento. En este ejemplo, todo el conjunto de datos pasará por la red neuronal 5 veces. Es importante tener cuidado con el número de épocas, ya que un número demasiado alto podría llevar a un sobreajuste (overfitting), en el cual el modelo se ajusta demasiado a los datos de entrenamiento y pierde capacidad de generalización.\n",
    "\n",
    "- `batch_size=64`: Especifica el tamaño del lote (batch). Esto significa que el modelo tomará 64 ejemplos de los datos de entrenamiento a la vez y los usará para actualizar los pesos. Un tamaño de lote más pequeño significa que el modelo se actualizará con más frecuencia, lo que puede ser beneficioso para la convergencia, pero también más costoso computacionalmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1918 - accuracy: 0.9398\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0517 - accuracy: 0.9839\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0373 - accuracy: 0.9884\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0300 - accuracy: 0.9905\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0224 - accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f033cf5a080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9898\n",
      "Test accuracy: 0.989799976348877\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la precisión del modelo en los datos de prueba\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deme/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo en un archivo\n",
    "model.save('numeros.h5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando la red y haciendo predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagen = test_images[4].reshape(28, 28)\n",
    "plt.imshow(imagen, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19607843],\n",
       "        [0.8784314 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.27450982],\n",
       "        [0.11372549],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.4745098 ],\n",
       "        [0.90588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5803922 ],\n",
       "        [0.65882355],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568628],\n",
       "        [0.7647059 ],\n",
       "        [0.90588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3764706 ],\n",
       "        [0.8235294 ],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.27058825],\n",
       "        [0.9882353 ],\n",
       "        [0.5254902 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.44705883],\n",
       "        [0.9882353 ],\n",
       "        [0.08235294],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1764706 ],\n",
       "        [0.9254902 ],\n",
       "        [0.8509804 ],\n",
       "        [0.04705882],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7529412 ],\n",
       "        [0.9882353 ],\n",
       "        [0.08235294],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.65882355],\n",
       "        [0.96862745],\n",
       "        [0.20784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [1.        ],\n",
       "        [0.99215686],\n",
       "        [0.08235294],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.32941177],\n",
       "        [0.9490196 ],\n",
       "        [0.827451  ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5529412 ],\n",
       "        [0.99215686],\n",
       "        [0.7411765 ],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6627451 ],\n",
       "        [0.9882353 ],\n",
       "        [0.41568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1254902 ],\n",
       "        [0.9098039 ],\n",
       "        [0.98039216],\n",
       "        [0.25882354],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05882353],\n",
       "        [0.88235295],\n",
       "        [0.9882353 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5254902 ],\n",
       "        [0.9882353 ],\n",
       "        [0.827451  ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08627451],\n",
       "        [0.9882353 ],\n",
       "        [0.6431373 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6627451 ],\n",
       "        [0.9882353 ],\n",
       "        [0.654902  ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.03529412],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.07058824],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08627451],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.41960785],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6627451 ],\n",
       "        [0.9882353 ],\n",
       "        [0.78039217],\n",
       "        [0.33333334],\n",
       "        [0.33333334],\n",
       "        [0.33333334],\n",
       "        [0.33333334],\n",
       "        [0.5058824 ],\n",
       "        [0.6431373 ],\n",
       "        [0.7647059 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.41568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.16078432],\n",
       "        [0.6666667 ],\n",
       "        [0.9607843 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9098039 ],\n",
       "        [0.90588236],\n",
       "        [0.9843137 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19215687],\n",
       "        [0.32941177],\n",
       "        [0.32941177],\n",
       "        [0.32941177],\n",
       "        [0.32941177],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6313726 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.49803922],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.1764706 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5019608 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.49803922],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5294118 ],\n",
       "        [0.9882353 ],\n",
       "        [0.95686275],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.9098039 ],\n",
       "        [0.9254902 ],\n",
       "        [0.43529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7019608 ],\n",
       "        [0.25882354],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "Dígito predicho: 4\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el modelo desde el archivo\n",
    "modelo_cargado = load_model('numeros.h5')\n",
    "\n",
    "# Tomamos una imagen del conjunto de pruebas (por ejemplo la primera)\n",
    "nueva_imagen = test_images[4]\n",
    "\n",
    "# Aumentamos la dimensión de la imagen para que tenga la forma (1, 28, 28, 1) requerida por el modelo\n",
    "nueva_imagen = np.expand_dims(nueva_imagen, axis=0)\n",
    "\n",
    "# Hacemos la predicción usando el modelo cargado\n",
    "predicciones = modelo_cargado.predict(nueva_imagen)\n",
    "\n",
    "# Obtenemos el dígito con la mayor probabilidad\n",
    "digito_predicho = np.argmax(predicciones)\n",
    "\n",
    "print(f'Dígito predicho: {digito_predicho}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'numeros.h5' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(\"numeros.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
